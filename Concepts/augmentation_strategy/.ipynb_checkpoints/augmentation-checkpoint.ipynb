{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook demonstrates different augmentation strategy\n",
    "  - [x] random swap \n",
    "  - [x] random delete\n",
    "  - [x] google translate\n",
    "  - [ ] random insertion\n",
    "    \n",
    "check out https://github.com/maelfabien/maelfabien.github.io/blob/9f2eb5092748a7cd8a7c964a7bda4968b65c4935/_posts/2019-10-28-NLP_8.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:10.375451Z",
     "start_time": "2021-01-08T10:25:10.002218Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:10.395907Z",
     "start_time": "2021-01-08T10:25:10.393538Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:11.512002Z",
     "start_time": "2021-01-08T10:25:10.428982Z"
    }
   },
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:11.533813Z",
     "start_time": "2021-01-08T10:25:11.531495Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:11.554098Z",
     "start_time": "2021-01-08T10:25:11.551599Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.596289Z",
     "start_time": "2021-01-08T10:25:11.575059Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.620539Z",
     "start_time": "2021-01-08T10:25:14.618571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.643820Z",
     "start_time": "2021-01-08T10:25:14.641614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.789070Z",
     "start_time": "2021-01-08T10:25:14.666274Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.809681Z",
     "start_time": "2021-01-08T10:25:14.807967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7854\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.860494Z",
     "start_time": "2021-01-08T10:25:14.830374Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.893651Z",
     "start_time": "2021-01-08T10:25:14.890165Z"
    }
   },
   "outputs": [],
   "source": [
    "# randomly delete words from a sentence with a given probability\n",
    "\n",
    "def random_deletion(sentence, p=0.5): \n",
    "    # return if single word\n",
    "    if len(sentence) == 1: \n",
    "        return sentence\n",
    "    # delete words\n",
    "    remaining = list(filter(lambda x: random.uniform(0,1) > p, sentence)) \n",
    "    # if nothing left, sample a random word\n",
    "    if len(remaining) == 0: \n",
    "        return [] \n",
    "    else:\n",
    "        return remaining\n",
    "    \n",
    "\n",
    "# randomly swap a pair of words in a sentence for a given # of times\n",
    "\n",
    "def random_swap(sentence, n=5): \n",
    "    if len(sentence) < 2:\n",
    "        return sentence\n",
    "    length = range(len(sentence)) \n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(length, 2)\n",
    "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:14.926298Z",
     "start_time": "2021-01-08T10:25:14.920300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'vordergrund',\n",
       " 'im',\n",
       " 'spielerin',\n",
       " 'einer',\n",
       " 'mit',\n",
       " 'roller-derby-spiel',\n",
       " 'einem',\n",
       " 'bei',\n",
       " 'actionfoto',\n",
       " 'ein']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = random.randint(0,len(train_data))\n",
    "sentence = train_data.examples[index].src\n",
    "list(filter(lambda x: random.uniform(0,1) > 0, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:25:16.096444Z",
     "start_time": "2021-01-08T10:25:14.945684Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/deep/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import google_trans_new\n",
    "from google_trans_new import google_translator\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "# translate a sentence to a random language,\n",
    "# and translate back to original language\n",
    "\n",
    "def back_translate(sentence, p=0.1, lang=\"en\"):\n",
    "    sentence = [str(i) for i in sentence]\n",
    "    # do nothing with probability of 1-p\n",
    "    if random.uniform(0,1) > p:\n",
    "        return sentence\n",
    "    \n",
    "    # combine tokenized sentence into one string\n",
    "    sentence = \" \".join(sentence)\n",
    "    print(sentence)\n",
    "    # instantiate translator\n",
    "    translator = google_translator()\n",
    "    \n",
    "    # choose a target language\n",
    "    available_langs = list(google_trans_new.LANGUAGES.keys())\n",
    "    trans_lang = random.choice(available_langs)\n",
    "    \n",
    "    # translate to the target language\n",
    "    translations = translator.translate(sentence, lang_tgt=trans_lang)\n",
    "    \n",
    "    # translate back to original language\n",
    "    translations_en_random = translator.translate(translations, lang_src=trans_lang, lang_tgt=lang)\n",
    "    \n",
    "    # select only one translation\n",
    "    if len(translations_en_random) > 1:\n",
    "        translations_en_random = translations_en_random[0]\n",
    "        \n",
    "    return word_tokenize(translations_en_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T10:26:18.582309Z",
     "start_time": "2021-01-08T10:26:18.016363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vordergrund im spielerin einer mit roller-derby-spiel einem bei actionfoto ein\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translate(sentence[1:], p=.9, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
