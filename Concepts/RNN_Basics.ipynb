{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits:<br>\n",
    "https://www.cnblogs.com/tolshao/p/buildingarecurrentneuralnetworkstepbystepv3b.html\n",
    "https://datascience-enthusiast.com/DL/Building_a_Recurrent_Neural_Network-Step_by_Step_v1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Recurrent Neural Network\n",
    "\n",
    "Everytime I come back to some NLP problem i realize that i need to cover RNN/LSTM from beginning again. So i decided to make this notebook which talks about RNN and atleast points to things that need to be understood to understand a working example of RNN/LSTM.<br><br>\n",
    "In short this notebook covers the following \n",
    "\n",
    "- Why RNN and what kind of problem could be solved using RNN\n",
    "- RNN architecture unrolled with time explanation\n",
    "- RNN forward propagation eqn with example weights\n",
    "- RNN coding example includes building a RNN cell from scratch and then use Pytorch to implement the same.\n",
    "- RNN backpropagation and it's shortcomings(like back propagation through time(BPTT) and Truncated BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why RNN\n",
    "\n",
    "In a problem like language translate, say you are translating from english to bengali, the input and output length could be different. So in this kind of problem we can't use a traditional CNN/ANN directly because the input size is variable.\n",
    "\n",
    "Also if you want to predict the next word in a sentence it is important to know the words before it(context). So we need a network which has \"memory\" which captures information about what has been calculated so far.\n",
    "\n",
    "## What is RNN\n",
    "A recurrent neural network is a neural network that is specialized for processing a sequence of data x(t)= x(1), . . . , x(τ) with the time step index t ranging from 1 to τ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN architecture\n",
    "\n",
    "Rnn architecture could be divided into 2 parts.RNN cell and the RNN model where multiple RNN cells are connected\n",
    "\n",
    "## RNN Cell:\n",
    "\n",
    "![RNN Cell](./images/rnn_cell.png)\n",
    "\n",
    "**Figure 3**: Basic RNN cell. Takes as input  x⟨t⟩  (current input) and  a⟨t−1⟩  (previous hidden state containing information from the past), and outputs  a⟨t⟩  which is given to the next RNN cell and also used to predict  y⟨t⟩\n",
    "\n",
    "Wax : Weight matrix multiplying the input the hidden layer.<br>\n",
    "Waa : Weight matrix multiplying the previous the hidden layer(h(t-1)) to current hidden layer(ht)<br>\n",
    "Wya : Weight matrix multiplying the output of the hidden layer to the output??(why can't we take the op directly)<br>\n",
    "xt  : One Input sequence to the rnn cell at timestep t   <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Example 1:\n",
    "\n",
    "Since you now have a basic idea, let’s break down the execution process with an example. Say your batch size is 6, RNN size is 7(so basically a(t) is 7 which means we are using a hidden layer of size 7),<br>\n",
    "the number of time steps/segments you would include in one input 5(each time step could be thought as processing of one word which has a embedding dim or feature size 3) <br>\n",
    "and the number of features in one time step is 3. <br>\n",
    "If this is the case, your input tensor (matrix) shape for one batch would look something like this:\n",
    "Tensor shape of one batch = (6,5,3)\n",
    "The data inside a batch would look something like this:\n",
    "\n",
    "![RNN model](./images/rnn_input.jpeg)\n",
    "\n",
    "But when the RNN starts to process the data it will unroll and produce outputs as shown below:\n",
    "\n",
    "<div>\n",
    "<img src=\"./images/rnn_unroll.png\" width=\"1000\" height=\"1000\" alt=\"rnn_unroll\"/>\n",
    "</div>\n",
    "\n",
    "<!-- ![RNN model](./images/rnn_unroll.png){height=400px width=500px} -->\n",
    "\n",
    "Couple of things to notice from the unrolled rnn image above:\n",
    "\n",
    "The input size is (6,5,3) --> (batch_size,time_step,feature_length). let's say we are feeding something like \"My name is Trinanjan\", here we have 4 words, so time_step is 4 and each word could be represented by some embedding and we have to specify that dimension. and if we process a series of sentences then we have to specify batch size.<br>\n",
    "\n",
    "The output size is (6,5,7) --> (batch_size,time_step,rnn_output)\n",
    "\n",
    "we are feeding one input of size (1,3) at time step t. Now let's say the hidden layer size is 7.That is essentially we are using 7 nodes in the hidden layer. In this picture above we can see that the rnn output size is also same i.e 7 but it could vary. Let's say you define RNN hidden layer size as 100 and you have 10 output classes. In that case the Ow weight matix will have the dimension such that it comes out 10 from 100.\n",
    "\n",
    "Also let's say we have one output at time t-1 , now when I pass this to the next layer hidden state notice i use hw[or Waa] weight to multiply and then the output goes to the next layer. I was wondering why can't i just pass it to the next layer directly. I guess we need to use these weight because weights are the one that is being learned.\n",
    "\n",
    "So to sum up we have 3 sets of weight hw(Waa) then hx(Wax) and hy(Wya). Important thing to remember here is that these weights are shared meaning we don't use separate sets of weight at each time step.Other we will have huge number of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T13:51:14.515181Z",
     "start_time": "2020-12-18T13:51:14.513733Z"
    }
   },
   "outputs": [],
   "source": [
    "## NOTE : according to the picture above we have 3 weight matrices. \n",
    "# one for input to rnn hidden layer\n",
    "# one for rnn hidden output to the next rnn timestep hidden output\n",
    "# one for rnn output to convert to hidden state output to final oputput as you require\n",
    "# ideally we should have 3 biases but in this example we are using only 2\n",
    "# this example shows the equation with all 3 biases https://towardsdatascience.com/all-you-need-to-know-about-rnns-e514f0b00c7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:13:15.766518Z",
     "start_time": "2020-12-18T15:13:15.759633Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN One cell Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:06:43.919304Z",
     "start_time": "2020-12-18T16:06:43.907744Z"
    }
   },
   "outputs": [],
   "source": [
    "# RNN one cell forward propagation\n",
    "\n",
    "def rnn_cell_forward(xt,a_prev,parameters):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of RNN-cell as described in \n",
    "    Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    xt -- input data at timestep \"t\", numpy array of shape(n_x,m)\n",
    "    a_prev -- Hidden state at timestep \"t-1\", numpy array of shape(n_a,m)\n",
    "    \n",
    "    parameters -- python dict containing :\n",
    "        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a,n_x)\n",
    "        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y,n_a)\n",
    "        ba  -- Bias for hidden layer, numpy array of shape (n_a,1)\n",
    "        by  -- Bias relating the hidden-state to the output, numpy array of shape (n_y,1)\n",
    "    \n",
    "    Returns:\n",
    "    a_next -- next hidden state, shape (n_a,m)\n",
    "    yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\n",
    "    chche -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve params from \"parameters\" dict\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    ### MAIN CODE ###\n",
    "    \n",
    "    # compute next activation state using the formula given above\n",
    "    a_next = np.tanh(np.dot(Waa, a_prev) + np.dot(Wax, xt) + ba)\n",
    "    # compute output of the current cell using the formula given above\n",
    "    yt_pred = torch.nn.Softmax(np.dot(Wya, a_next) + by)\n",
    "    yt_pred =  yt_pred.dim\n",
    "    \n",
    "    ### END OF MAIN ###\n",
    "    \n",
    "    # store values you need for backward propagation in cache\n",
    "    cache = (a_next,a_prev,xt,parameters)\n",
    "    \n",
    "    return a_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:06:47.589425Z",
     "start_time": "2020-12-18T16:06:47.579496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_next[4] =  [ 0.06941064  0.02212489  0.43926328  0.78063373  0.95994735  0.82543454\n",
      " -0.98515698 -0.98667449  0.54886588 -0.05653418]\n",
      "a_next.shape =  (5, 10)\n",
      "yt_pred[1] = [[ 0.9092852  -1.59848365  1.36423616 -0.57958794 -0.15054085 -0.66888275\n",
      "  -2.65403086  0.16586335 -0.94538287  0.45756809]\n",
      " [ 1.78534977  1.4748327   1.36450624  3.15882046  3.19210891  2.53689657\n",
      "   0.694187    0.11218914  2.34380738  1.0752556 ]]\n",
      "yt_pred.shape =  (2, 10)\n"
     ]
    }
   ],
   "source": [
    "m = 10 # number_of_example\n",
    "input_feature_size = 3 # each word could be represented to a vector of size 3\n",
    "hidden_size = 5 # hidden layer dimensions\n",
    "output_size = 2 # how many output you want\n",
    "xt = np.random.randn(input_feature_size,m) # 10 examples with each having a feature size of 3 \n",
    "a_prev = np.random.randn(5,m) # m examples with 5 nodes\n",
    "Waa = np.random.randn(hidden_size,hidden_size) # hidden to hidden\n",
    "Wax = np.random.randn(hidden_size,input_feature_size) # input to hidden\n",
    "Wya = np.random.randn(output_size,hidden_size) # hidden to output\n",
    "ba = np.random.randn(hidden_size,1) # hidden to input\n",
    "by = np.random.randn(output_size,1) # hidden to output\n",
    "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a_next, yt_pred, cache = rnn_cell_forward(xt,a_prev,parameters)\n",
    "print(\"a_next[4] = \", a_next[4])\n",
    "print(\"a_next.shape = \", a_next.shape)\n",
    "print(\"yt_pred[1] =\", yt_pred)\n",
    "print(\"yt_pred.shape = \", yt_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:06:52.320472Z",
     "start_time": "2020-12-18T16:06:52.315505Z"
    }
   },
   "outputs": [],
   "source": [
    "## Need to go through ANN weight initialization dimensions what does each row and column represent \n",
    "## each coulmn is one output for one example or each row is one output for one example \n",
    "## check out andrew ng lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rnn Full Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see RNN as the repetion of of the cell you've just built. If your input sequence of data is carried over 10 time steps, then you will copy thr RNN cell 10 times. Each cell takes as input the hidden state from the previous cell (a(t-1)) and the current timestep xt. we have output as yt and hidden state output as at\n",
    "\n",
    "## RNN model unrolled in time:\n",
    "\n",
    "![RNN model](./images/rnn_model.png)\n",
    "**Figure 3**: Basic RNN. The input sequence  x=(x⟨1⟩,x⟨2⟩,...,x⟨Tx⟩)  is carried over  Tx  time steps. The network outputs  y=(y⟨1⟩,y⟨2⟩,...,y⟨Tx⟩) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "    1. Create a vector of zeros(a) that will store all the hidden states computed by RNN.\n",
    "    2. Initialize the \"next\" hidden state as a0 as zero matrix. this will as first timestep previous input \n",
    "    3. Start looping over each time step and each timestep should call the rnn_cell_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:07:36.044604Z",
     "start_time": "2020-12-18T16:07:36.038557Z"
    }
   },
   "outputs": [],
   "source": [
    "# RNN full forward propagation\n",
    "\n",
    "def rnn_forward(xt,a0,parameters):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implements a forward propagation as desribed in the figure above\n",
    "    \n",
    "    Arguments:\n",
    "    x -- input data for timesteps T_x  numpy array of shape(n_x,m,T_x)\n",
    "    a0 -- initial hidden state, numpy array of shape(n_a,m)\n",
    "    \n",
    "    Parameters -- python dict containing :\n",
    "        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a,n_x)\n",
    "        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y,n_a)\n",
    "        ba  -- Bias for hidden layer, numpy array of shape (n_a,1)\n",
    "        by  -- Bias relating the hidden-state to the output, numpy array of shape (n_y,1)\n",
    "    \n",
    "    Returns:\n",
    "    a --Hidden states for every time-step, numpy array of shape (n_a,m,T_x)\n",
    "    yt_pred -- prediction for every time-step, numpy array of shape (n_y, m,T_x)\n",
    "    chche -- tuple of values needed for the backward pass, contains (list of caches, same as timesteps)\n",
    "    \n",
    "    \"\"\" \n",
    "    # initialize caches which will contail the list of all caches\n",
    "    caches = []\n",
    "    \n",
    "    # retrieve dimensions from shapes of x and Wy\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters[\"Wya\"].shape\n",
    "    ### MAIN CODE HERE ###\n",
    "    \n",
    "    # initialize \"a\" and \"y\" with zeros \n",
    "    a = np.zeros((n_a,m,T_x)) \n",
    "    y_pred = np.zeros((n_y,m,T_x))\n",
    "    a_next = a0\n",
    "    \n",
    "    # loop over time-steps\n",
    "    for t in range(T_x):\n",
    "        # update next hidden state, compute prediction, get the cache\n",
    "        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t],a_next,parameters)\n",
    "        # save the value of the new \"next\" hidden state in a\n",
    "        a[:,:,t] = a_next\n",
    "        # save the value of pred\n",
    "        y_pred[:,:,t] = yt_pred\n",
    "        # save cache\n",
    "        caches.append(cache)\n",
    "    # store values for backpropagation\n",
    "    caches = (caches,x)\n",
    "    return a, y_pred, caches\n",
    "    ### MAIN ENDS HERE ###\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:07:36.308614Z",
     "start_time": "2020-12-18T16:07:36.292410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[4][1] =  [ 7.84026820e-01 -9.81241829e-01 -2.99758431e-04 -9.89749262e-01]\n",
      "a.shape =  (5, 10, 4)\n",
      "y_pred[1][3] = [-0.75022292  3.11688946  2.97666446 -1.9297936 ]\n",
      "y_pred.shape =  (2, 10, 4)\n",
      "caches[1][1][3] = [-1.04936032  0.76025175 -0.7970639  -0.51758053]\n",
      "len(caches) =  2\n"
     ]
    }
   ],
   "source": [
    "m = 10 # number_of_example\n",
    "input_feature_size = 3 # each word could be represented to a vector of size 3\n",
    "hidden_size = 5 # hidden layer dimensions\n",
    "output_size = 2 # how many output you want\\\n",
    "time_step_size = 4 # time steps\n",
    "\n",
    "x = np.random.randn(input_feature_size,m,time_step_size) # 10 examples with each having a feature size of 3 \n",
    "a0 = np.random.randn(5,m) # m examples with 5 nodes\n",
    "Waa = np.random.randn(hidden_size,hidden_size) # hidden to hidden\n",
    "Wax = np.random.randn(hidden_size,input_feature_size) # input to hidden\n",
    "Wya = np.random.randn(output_size,hidden_size) # hidden to output\n",
    "ba = np.random.randn(hidden_size,1) # hidden to input\n",
    "by = np.random.randn(output_size,1) # hidden to output\n",
    "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a, y_pred, caches = rnn_forward(x,a0,parameters)\n",
    "print(\"a[4][1] = \", a[4][1])\n",
    "print(\"a.shape = \", a.shape)\n",
    "print(\"y_pred[1][3] =\", y_pred[1][3])\n",
    "print(\"y_pred.shape = \", y_pred.shape)\n",
    "print(\"caches[1][1][3] =\", caches[1][1][3])\n",
    "print(\"len(caches) = \", len(caches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
